# web_interface.py - Streamlit ì›¹ ì¸í„°í˜ì´ìŠ¤

import streamlit as st
import sys
import os
sys.path.append('src')

from src.core import PaperSections
from treellm_system import TreeLLMSystem
from utils.pdf_processor import PDFProcessor, RelatedPaperProcessor
import json

def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if 'analysis_results' not in st.session_state:
        st.session_state.analysis_results = None
    if 'treellm' not in st.session_state:
        st.session_state.treellm = TreeLLMSystem()

def display_header():
    """í—¤ë” í‘œì‹œ"""
    st.set_page_config(
        page_title="TreeLLM - AI Paper Analyzer",
        page_icon="ğŸŒ³",
        layout="wide"
    )
    
    st.title("ğŸŒ³ TreeLLM")
    st.subtitle("AI Agent ê¸°ë°˜ ë…¼ë¬¸ ë¶„ì„ ì‹œìŠ¤í…œ")
    st.markdown("---")

def paper_input_section():
    """ë…¼ë¬¸ ì…ë ¥ ì„¹ì…˜"""
    st.header("ğŸ“„ ë…¼ë¬¸ ì…ë ¥")
    
    input_method = st.radio(
        "ì…ë ¥ ë°©ì‹ ì„ íƒ:",
        ["í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥", "PDF íŒŒì¼ ì—…ë¡œë“œ"]
    )
    
    paper_sections = None
    
    if input_method == "í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥":
        paper_sections = text_input_interface()
    else:
        paper_sections = pdf_upload_interface()
    
    return paper_sections

def text_input_interface():
    """í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥ ì¸í„°í˜ì´ìŠ¤"""
    col1, col2 = st.columns(2)
    
    with col1:
        introduction = st.text_area(
            "Introduction",
            height=150,
            placeholder="ë…¼ë¬¸ì˜ Introduction ì„¹ì…˜ì„ ì…ë ¥í•˜ì„¸ìš”..."
        )
        
        method = st.text_area(
            "Method",
            height=150,
            placeholder="Method ì„¹ì…˜ì„ ì…ë ¥í•˜ì„¸ìš”..."
        )
        
        discussion = st.text_area(
            "Discussion",
            height=150,
            placeholder="Discussion ì„¹ì…˜ì„ ì…ë ¥í•˜ì„¸ìš”..."
        )
    
    with col2:
        related_work = st.text_area(
            "Related Work",
            height=150,
            placeholder="Related Work ì„¹ì…˜ì„ ì…ë ¥í•˜ì„¸ìš”..."
        )
        
        experiments = st.text_area(
            "Experiments",
            height=150,
            placeholder="Experiments ì„¹ì…˜ì„ ì…ë ¥í•˜ì„¸ìš”..."
        )
        
        conclusion = st.text_area(
            "Conclusion",
            height=150,
            placeholder="Conclusion ì„¹ì…˜ì„ ì…ë ¥í•˜ì„¸ìš”..."
        )
    
    if any([introduction, related_work, method, experiments, discussion, conclusion]):
        return PaperSections(
            introduction=introduction,
            related_work=related_work,
            method=method,
            experiments=experiments,
            discussion=discussion,
            conclusion=conclusion
        )
    
    return None

def pdf_upload_interface():
    """PDF ì—…ë¡œë“œ ì¸í„°í˜ì´ìŠ¤"""
    uploaded_file = st.file_uploader(
        "ë…¼ë¬¸ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=['pdf'],
        help="PDFì—ì„œ ìë™ìœ¼ë¡œ ì„¹ì…˜ì„ ì¶”ì¶œí•©ë‹ˆë‹¤"
    )
    
    if uploaded_file is not None:
        with st.spinner("PDF íŒŒì¼ ì²˜ë¦¬ ì¤‘..."):
            try:
                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                temp_path = f"temp_{uploaded_file.name}"
                with open(temp_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                
                # ì„¹ì…˜ ì¶”ì¶œ
                sections_dict = PDFProcessor.extract_sections_from_pdf(temp_path)
                
                # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
                metadata = PDFProcessor.extract_metadata_from_pdf(temp_path)
                
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                os.remove(temp_path)
                
                # ê²°ê³¼ í‘œì‹œ
                st.success("âœ… PDF ì²˜ë¦¬ ì™„ë£Œ!")
                
                if metadata.get('title'):
                    st.info(f"ğŸ“– ì œëª©: {metadata['title']}")
                if metadata.get('page_count'):
                    st.info(f"ğŸ“„ í˜ì´ì§€ ìˆ˜: {metadata['page_count']}")
                
                # ì¶”ì¶œëœ ì„¹ì…˜ ë¯¸ë¦¬ë³´ê¸°
                with st.expander("ì¶”ì¶œëœ ì„¹ì…˜ ë¯¸ë¦¬ë³´ê¸°"):
                    for section_name, content in sections_dict.items():
                        if content.strip():
                            st.text_area(
                                f"{section_name.title()}",
                                value=content[:200] + "..." if len(content) > 200 else content,
                                height=80,
                                disabled=True
                            )
                
                return PaperSections(**sections_dict)
                
            except Exception as e:
                st.error(f"âŒ PDF ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    return None

def related_papers_section():
    """ê´€ë ¨ ë…¼ë¬¸ ì„¹ì…˜"""
    st.header("ğŸ“š ê´€ë ¨ ë…¼ë¬¸ ë¹„êµ (ì„ íƒì‚¬í•­)")
    
    with st.expander("ê´€ë ¨ ë…¼ë¬¸ ì—…ë¡œë“œ"):
        st.markdown("""
        ê´€ë ¨ ë…¼ë¬¸ë“¤ì„ ì—…ë¡œë“œí•˜ë©´ ë” ì •í™•í•œ ë¹„êµ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
        - ê¶Œì¥: 3-10í¸ì˜ ê´€ë ¨ ë…¼ë¬¸
        - ì§€ì› í˜•ì‹: PDF
        """)
        
        uploaded_papers = st.file_uploader(
            "ê´€ë ¨ ë…¼ë¬¸ PDF íŒŒì¼ë“¤",
            type=['pdf'],
            accept_multiple_files=True,
            help="ì—¬ëŸ¬ íŒŒì¼ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        )
        
        if uploaded_papers:
            st.success(f"âœ… {len(uploaded_papers)}í¸ì˜ ê´€ë ¨ ë…¼ë¬¸ ì—…ë¡œë“œë¨")
            
            # ê°„ë‹¨í•œ ì •ë³´ í‘œì‹œ
            for i, paper in enumerate(uploaded_papers, 1):
                st.text(f"{i}. {paper.name}")
            
            return uploaded_papers
    
    return None

def analysis_options_section():
    """ë¶„ì„ ì˜µì…˜ ì„¹ì…˜"""
    st.header("ğŸ” ë¶„ì„ ì˜µì…˜")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**USENIX ê¸°ì¤€ ê²€ì¦** (í•„ìˆ˜)")
        usenix_agents = st.multiselect(
            "USENIX Agent ì„ íƒ:",
            ["OriginalityAgent", "LessonExtractionAgent", "AssumptionAgent"],
            default=["OriginalityAgent", "LessonExtractionAgent"],
            help="USENIX Guidelines ê¸°ì¤€ìœ¼ë¡œ ë…¼ë¬¸ì„ í‰ê°€í•©ë‹ˆë‹¤"
        )
    
    with col2:
        st.markdown("**ì¶”ê°€ ë¶„ì„ ì˜µì…˜**")
        enable_comparison = st.checkbox(
            "ê´€ë ¨ ë…¼ë¬¸ ë¹„êµ ë¶„ì„", 
            help="ì—…ë¡œë“œëœ ê´€ë ¨ ë…¼ë¬¸ë“¤ê³¼ ë¹„êµí•©ë‹ˆë‹¤"
        )
        
        show_token_usage = st.checkbox(
            "í† í° ì‚¬ìš©ëŸ‰ í‘œì‹œ",
            help="ì˜ˆìƒ í† í° ì‚¬ìš©ëŸ‰ê³¼ ë¹„ìš©ì„ í‘œì‹œí•©ë‹ˆë‹¤"
        )
    
    return usenix_agents, enable_comparison, show_token_usage

def display_analysis_results(results):
    """ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    st.header("ğŸ“Š ë¶„ì„ ê²°ê³¼")
    
    # ì „ì²´ ìš”ì•½
    summary = results['integrated_summary']
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì „ì²´ ì ìˆ˜", f"{summary['overall_score']:.2f}/5.0")
    with col2:
        st.metric("ê°œì„  ì œì•ˆ", f"{summary['total_suggestions']}ê°œ")
    with col3:
        improvement_count = len(summary['priority_improvements'])
        st.metric("ìš°ì„  ê°œì„ ", f"{improvement_count}ê°œ")
    
    # Agentë³„ ìƒì„¸ ê²°ê³¼
    st.subheader("ğŸ¤– Agentë³„ ë¶„ì„ ê²°ê³¼")
    
    for agent_name, result in results['usenix_analysis'].items():
        with st.expander(f"{agent_name} ê²°ê³¼", expanded=True):
            
            # ì ìˆ˜ í‘œì‹œ
            st.markdown("**ğŸ“ˆ ì ìˆ˜**")
            score_cols = st.columns(len(result.scores))
            
            for i, (criterion, score) in enumerate(result.scores.items()):
                with score_cols[i]:
                    # ì ìˆ˜ì— ë”°ë¥¸ ìƒ‰ìƒ
                    if score >= 4.0:
                        color = "ğŸŸ¢"
                    elif score >= 3.0:
                        color = "ğŸŸ¡"
                    else:
                        color = "ğŸ”´"
                    
                    st.metric(
                        criterion,
                        f"{score:.1f}",
                        delta=None,
                        help=f"5ì  ë§Œì  ê¸°ì¤€ {color}"
                    )
            
            # ë°œê²¬ì‚¬í•­
            st.markdown("**ğŸ” ì£¼ìš” ë°œê²¬ì‚¬í•­**")
            for finding in result.findings:
                st.write(f"â€¢ {finding}")
            
            # ê°œì„  ì œì•ˆ
            st.markdown("**ğŸ’¡ ê°œì„  ì œì•ˆ**")
            for suggestion in result.suggestions:
                st.write(f"â€¢ {suggestion}")
    
    # ê´€ë ¨ ë…¼ë¬¸ ë¹„êµ ê²°ê³¼
    if results.get('comparison_analysis'):
        st.subheader("ğŸ“š ê´€ë ¨ ë…¼ë¬¸ ë¹„êµ ê²°ê³¼")
        comp_result = results['comparison_analysis']
        
        with st.expander("ë¹„êµ ë¶„ì„ ê²°ê³¼", expanded=True):
            # ë¹„êµ ì ìˆ˜
            st.markdown("**ğŸ“Š ë¹„êµ ì ìˆ˜**")
            comp_cols = st.columns(len(comp_result.scores))
            
            for i, (criterion, score) in enumerate(comp_result.scores.items()):
                with comp_cols[i]:
                    st.metric(criterion, f"{score:.1f}/5.0")
            
            # ë¹„êµ ë°œê²¬ì‚¬í•­
            st.markdown("**ğŸ” ë¹„êµ ë¶„ì„ ë°œê²¬ì‚¬í•­**")
            for finding in comp_result.findings:
                st.write(f"â€¢ {finding}")
    
    # ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
    st.subheader("ğŸ’¾ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
    
    # JSON í˜•íƒœë¡œ ë‹¤ìš´ë¡œë“œ
    results_json = json.dumps(results, ensure_ascii=False, indent=2, default=str)
    
    st.download_button(
        label="ğŸ“¥ ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (JSON)",
        data=results_json,
        file_name="treellm_analysis_results.json",
        mime="application/json"
    )

def sidebar_info():
    """ì‚¬ì´ë“œë°” ì •ë³´"""
    st.sidebar.title("â„¹ï¸ TreeLLM ì •ë³´")
    
    st.sidebar.markdown("""
    ### ğŸ“‹ ì§€ì› ê¸°ëŠ¥
    - USENIX Guidelines ê¸°ì¤€ ê²€ì¦
    - Agent ê¸°ë°˜ ì „ë¬¸ ë¶„ì„
    - ê´€ë ¨ ë…¼ë¬¸ ë¹„êµ ë¶„ì„
    - PDF ìë™ ì„¹ì…˜ ì¶”ì¶œ
    - ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
    
    ### ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ Agent
    - **OriginalityAgent**: ë…ì°½ì„± í‰ê°€
    - **LessonExtractionAgent**: êµí›ˆ ì¶”ì¶œ
    - **AssumptionAgent**: ê°€ì •ì‚¬í•­ ë¶„ì„
    
    ### ğŸ’¡ ì‚¬ìš© íŒ
    1. ë…¼ë¬¸ì˜ ëª¨ë“  ì„¹ì…˜ì„ ì…ë ¥í•˜ì„¸ìš”
    2. ê´€ë ¨ ë…¼ë¬¸ì„ ì—…ë¡œë“œí•˜ë©´ ë” ì •í™•í•©ë‹ˆë‹¤
    3. ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
    """)
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("**ê°œë°œíŒ€**: TreeLLM Team")
    st.sidebar.markdown("**ë²„ì „**: v0.1.0")

def main():
    """ë©”ì¸ ì›¹ ì¸í„°í˜ì´ìŠ¤"""
    init_session_state()
    display_header()
    
    # 1. ë…¼ë¬¸ ì…ë ¥
    paper_sections = paper_input_section()
    
    # 2. ê´€ë ¨ ë…¼ë¬¸ ì—…ë¡œë“œ
    uploaded_papers = related_papers_section()
    
    # 3. ë¶„ì„ ì˜µì…˜
    selected_agents, enable_comparison, show_token_usage = analysis_options_section()
    
    # 4. í† í° ì‚¬ìš©ëŸ‰ í‘œì‹œ
    if show_token_usage and paper_sections:
        st.subheader("ğŸ’° ì˜ˆìƒ í† í° ì‚¬ìš©ëŸ‰")
        token_usage = st.session_state.treellm.get_agent_token_usage()
        
        total_tokens = sum(token_usage[agent] for agent in selected_agents if agent in token_usage)
        estimated_cost = total_tokens * 0.00003  # GPT-4 ê¸°ì¤€
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ì˜ˆìƒ í† í°", f"{total_tokens:,}")
        with col2:
            st.metric("ì˜ˆìƒ ë¹„ìš©", f"${estimated_cost:.3f}")
        
        with st.expander("Agentë³„ í† í° ì‚¬ìš©ëŸ‰"):
            for agent in selected_agents:
                if agent in token_usage:
                    st.text(f"{agent}: {token_usage[agent]:,} í† í°")
    
    # 5. ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
    st.markdown("---")
    
    if st.button("ğŸš€ ë…¼ë¬¸ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
        if not paper_sections:
            st.error("âŒ ë…¼ë¬¸ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
        
        if not selected_agents:
            st.error("âŒ ìµœì†Œ í•˜ë‚˜ì˜ USENIX Agentë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return
        
        # ë¶„ì„ ì‹¤í–‰
        with st.spinner("ğŸ”„ ë…¼ë¬¸ ë¶„ì„ ì¤‘... (1-2ë¶„ ì†Œìš”)"):
            try:
                # ê´€ë ¨ ë…¼ë¬¸ ì²˜ë¦¬
                related_papers_data = None
                if uploaded_papers and enable_comparison:
                    # PDF ì²˜ë¦¬ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” RelatedPaperProcessor ì‚¬ìš©)
                    related_papers_data = [
                        {"title": paper.name, "year": 2023} 
                        for paper in uploaded_papers
                    ]
                
                # ë¶„ì„ ì‹¤í–‰
                results = st.session_state.treellm.analyze_paper(
                    paper_sections=paper_sections,
                    uploaded_papers=related_papers_data,
                    selected_agents=selected_agents
                )
                
                st.session_state.analysis_results = results
                st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
                
            except Exception as e:
                st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                return
    
    # 6. ê²°ê³¼ í‘œì‹œ
    if st.session_state.analysis_results:
        display_analysis_results(st.session_state.analysis_results)

if __name__ == "__main__":
    sidebar_info()
    main()
