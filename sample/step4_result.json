{
  "Conclusion": "```json\n{\n  \"section\": \"Conclusion\",\n  \"improved\": \"본 연구에서는 시각장애인의 보행 중 충돌 위험을 예측하기 위해 객체 인식, 충돌 가능 영역 정의, 깊이 추정 및 시계열 정보의 통합 모델을 제안하였다. 충돌 가능 영역과 깊이 정보를 입력 특성으로 포함시킴으로써, 단순 위치 기반의 예측보다 향상된 정확도와 정밀도를 달성하였다. 통계적 분석을 통해 이러한 입력 특성이 실제 충돌과 유의한 연관성을 지님을 입증하였다. 특히, 다양한 시간적 및 공간적 정보를 효과적으로 융합하여 위험 상황을 사전에 인지하고 예측할 수 있는 구조를 새롭게 제시함으로써 높은 실용적 가치를 입증하였다. 향후 거리 추정이 가능한 센서나 스테레오 카메라와 같은 보조 장비의 활용 시, 예측 정확도가 더욱 향상될 수 있을 것으로 기대된다.\"\n}\n```",
  "Introduction": "```json\n{\n  \"section\": \"Introduction\",\n  \"improved\": \"시각장애인의 독립적이고 안전한 보행은 그들의 삶의 질을 보장하기 위한 중요한 과제이다. 보행 과정에서 발생할 수 있는 장애물이나 이동체와의 충돌 위험은 생명과 직결되는 문제로, 이를 사전에 인식하고 예방하는 기술적 대응이 필수적이다. 최근 딥러닝 기반 객체 탐지 기술의 발전으로 다양한 환경에서 객체 인식이 가능해졌으나, 기존 보행 지원 시스템은 주로 단일 프레임 기반의 객체 판단에 의존하며, 시계열적 변화나 공간적 맥락을 충분히 고려하지 못하고 있다. 사람은 보행 중 무의식적으로 자신의 진행 방향을 기준으로 앞으로 지나갈 영역을 인지하며, 그 공간에서의 위험 요소를 회피하려는 경향이 있다. 본 연구는 이러한 인지적 직관을 수학적으로 모델링하여 사용자를 기준으로 정의된 '충돌 가능 영역' 개념을 중심으로 실제 보행 중 위험을 정량적으로 예측하는 모델을 제안한다. '충돌 가능 영역'은 카메라 시야각과 사용자의 체형 정보를 바탕으로 수학적으로 정의되며, 본 연구는 이 개념이 실제 보행 중 충돌과 통계적으로 유의미한 연관이 있음을 18만 개 이상의 시뮬레이션 시퀀스를 통해 입증하였다. 제안된 충돌 위험 예측 모델은 인식된 객체와 충돌 가능 영역 간의 겹침 정도(IoU)와 깊이 정보를 바탕으로 공간적, 시간적 특성을 추출하고, 이를 통합하여 충돌 가능성을 정량화한다. 본 논문의 주요 기여는 다음과 같다. 첫째, 시각장애인의 보행 중 충돌 위험을 정량화하기 위해 정의된 충돌 가능 영역의 유효성을 자체 수집 데이터를 통해 통계적으로 검증하여, 해당 영역 정보가 예측 지표로서 유의미함을 입증하였다. 둘째, 검증된 영역 관련 지표를 바탕으로 IoU 및 깊이 정보를 통합하여 설계한 충돌 예측 모델은 F1-score 0.7549의 성능을 기록하며 높은 정확도를 달성하였다. 본 연구는 2024년 과학기술정통신부 및 정보통신기획평가원의 SW중심대학사업 지원을 받아 수행되었으며, 셋째로 충돌 여부를 시계열 분류 문제로 정의하고 이를 실험적으로 평가하여, 실제 환경에서 활용 가능한 충돌 예측 모델의 가능성을 제시하였다.\"\n}\n```",
  "Discussion": "```json\n{\n  \"section\": \"Discussion\",\n  \"improved\": \"본 연구는 시각장애인의 보행 중 충돌 위험을 예측하기 위한 모델을 제안하였으며, 객체 인식, 충돌 가능 영역 정의, 깊이 추정, 시계열 정보를 통합하였다. 본 모델은 충돌 가능 영역과 해당 영역의 깊이 정보를 입력 특성으로 포함함으로써, 단순한 위치 기반 예측 방식보다 높은 정확도와 정밀도를 달성하였다. 통계적 분석을 통해 이러한 입력 특성이 실제 충돌과 유의미한 연관성이 있음을 입증하였다. 특히, 본 연구는 다양한 시간적 및 공간적 정보를 효과적으로 결합하여 위험 상황을 사전에 인지하고 예측할 수 있는 구조를 처음으로 제안하여, 그 실용적 가치가 크다. 더불어, 향후 거리 추정이 가능한 센서나 스테레오 카메라를 활용하면 예측 정확도가 더욱 향상될 것으로 기대된다.\"\n}\n```",
  "Related Work": "```json\n{\n  \"section\": \"Related Work\",\n  \"improved\": \"시각장애인을 위한 보행 보조 기술 연구는 주로 객체 인식 기술을 활용하여 장애물을 탐지하고, 이러한 정보를 기반으로 경고나 안내를 제공하는 데 중점을 두어왔다. 예를 들어, 시각장애인의 보행 보조를 위한 조도 적응형 실시간 객체 탐지 연구[1]에서는 YOLO를 사용하여 경고를 제공하는 객체 탐지 기법을 제안하였다. 딥러닝 기반의 보행 보조 시스템 연구[2]에서는 YOLO 모델을 통해 사람, 차량 등의 주요 객체를 인식하고 음성 피드백을 제공하는 시스템을 제시하였다. 더 나아가, Erdaw et al.[3]은 YOLO 모델에 Short-Term Memory (STM)를 결합하여 객체 이동 정보를 반영한 탐지 시스템을 개발하였다. 또한, GloSea6에서 YOLOv8을 활용한 연구[4]는 객체의 이동 방향, 크기 변화, 깊이를 추정하여 이미지의 위험도를 평가하였다. 기존의 연구들은 객체 인식, 위험도 추정, 보행 환경 고려 등 다양한 측면에서 시각장애인의 보행 안전성을 개선하려고 하였다. 그러나 대부분의 연구는 주로 객체 인식에 초점을 맞추며, 정적 위험 요소와 객체의 분류에 국한되는 경향이 있다. 특히, 비전 기반으로 탐지된 객체의 시간적 움직임을 분석하고 이를 통해 충돌 위험성을 정량화하는 연구는 부족한 실정이다. 본 연구는 연속된 프레임 간의 정보를 시간적 연속성에 따라 해석하여 충돌 가능성을 정량적으로 분석한다는 점에서 기존 연구와 차별성을 가진다.\"\n}\n```",
  "Abstract": "```json\n{\n  \"section\": \"Abstract\",\n  \"improved\": \"본 연구는 시각장애인의 보행 중 충돌 위험을 예측하기 위한 모델을 제안한다. 보행 시 개인은 본능적으로 자신의 경로 상의 공간을 인식하고, 그 공간 내에서 위험 요소를 감지하는 경향이 있다. 본 연구는 이러한 인지적 직관을 수학적으로 모델링하여 '충돌 가능 영역'을 정의하고, 사용자의 체형과 카메라 시야각을 기반으로 하는 모델을 개발하였다. 이 영역은 객체의 위치 정보, 영역과의 중첩 정도(IoU), 깊이 정보를 입력으로 활용한다. 자체 시뮬레이션 데이터를 통해 이 충돌 가능 영역이 실제 충돌과 얼마나 통계적으로 연관이 있는지를 검증한 결과, IoU 단일 지표만으로도 AUROC 0.702의 분류 성능을 보였다. 이러한 분석을 토대로, YOLO와 MiDaS를 통해 위치와 깊이 정보를 추출하여 시계열 입력으로 활용하였다. 위치, IoU, 깊이 정보는 각각 Conv1D와 Conv3D를 사용해 시공간적 특징을 추출하고, Conv1D–BiLSTM으로 시간적 패턴을 학습하여 충돌 여부를 이진 분류한다. 실험 결과, IoU와 깊이 정보를 함께 활용한 최종 모델은 F1-score 0.7549를 기록하며 높은 예측 성능을 보였다.\"\n}\n```",
  "Method": "```json\n{\n  \"section\": \"Method\",\n  \"improved\": \"본 연구는 시각 장애인의 보행 중 발생할 수 있는 충돌 위험을 예측하기 위해 객체 탐지, 깊이 추정 및 시계열 정보 분석을 통합하는 모델을 제안한다. 모델은 객체의 시계열적 움직임과 공간적 특성을 반영하여 미래의 충돌 가능성을 정량적으로 판단한다. 이를 위해 보행 환경에서의 위험 공간을 수학적으로 정의한 '충돌 가능 영역'을 주요 입력 특성으로 활용한다. 3.1 충돌 가능 영역 충돌 위험을 정량적으로 예측하기 위해 카메라 시야를 기준으로 고위험 공간을 정의하였다. 충돌 가능 영역은 사용자의 시야 높이, 어깨 너비, 카메라의 수평 및 수직 시야각(VFOV, HFOV)을 기반으로 계산되며, 실제 보행 경로 상에서 충돌 위험이 높은 영역을 시야 내 삼각형 형태로 모델링한 것이다. 충돌 가능 영역의 주요 변수로는 사용자의 시야 높이 , 카메라의 수직시야각 , 수평시야각 , 지면과 시야의 하단이 교차하는 수평거리 , 사용자 몸통의 너비 가 있다. 그림 1은 수직 시점에서 본 시야각의 예이며, 수평거리 는   cot  의 식으로 계산된다. 이는 사용자 기준으로 시야 높이 에서 시야의 하단 경계까지 이어지는 수직 시선과 지면이 이루는 삼각형을 기반으로 도출되었다. 그림 2는 수평 시점에서의 시야각을 나타내며, 앞서 구한 거리 를 통해 수평 시야 경계와 지면의 교차 지점에서의 수평 폭 는   tan  로 계산된다. 이를 통해 실제 공간에서의 충돌 가능 영역의 비율 tan  를 정의할 수 있다. 이러한 조합으로, 카메라 시야의 지평선 중심점과 시야 하단의 수평 폭 간의 연계를 설정한다. 그림 3은 충돌 가능 영역에 대한 카메라 시야와 실제 보행 환경의 도식을 포함한다. 3.2 모델 구조 모델 구조는 네 가지 주요 단계로 구성된다: 객체 인식, 깊이 추정, 시간 순 입력 처리, 충돌 위험 예측이다. 전체 시스템 흐름은 그림 4에 나타나 있다. 첫 번째 단계에서는 영상 스트림에서 각 프레임 단위로 객체를 인식하며, YOLO v11 기반 객체 탐지 모델을 활용하여 사람, 차량, 장애물을 검출하고 위치 정보를 바운딩 박스로 추출한다. 객체의 좌표 정보와 충돌 가능 영역과의 IoU(Intersection over Union)를 계산하여 위험도 분석의 입력으로 사용한다. 두 번째 단계에서는 이미지의 각 픽셀에 대한 상대적 거리(깊이)를 예측하여 위험 판단의 정밀도를 향상시킨다. MiDaS 기반의 단일 이미지 깊이 추정 모델을 사용하여 프레임 입력으로 각 픽셀의 깊이를 예측하고, 충돌 가능 영역에 해당하는 픽셀을 선택적으로 추출하여 깊이 정보를 활용한다. 세 번째 단계에서는 객체 정보와 깊이 정보를 시간 순으로 분석하기 위해 고정 길이의 슬라이딩 윈도우 큐(queue)를 사용한다. 각 프레임에서의 객체 위치, 충돌 가능 영역과의 IoU, 영역의 깊이 정보가 큐에 저장되며 새로운 프레임이 추가될 때 오래된 데이터는 제거된다. 이는 객체의 움직임과 위험 상황 변화를 효과적으로 파악하기 위함이다. 마지막 단계에서는 큐에 저장된 시계열 데이터를 바탕으로 향후 충돌 위험을 예측한다. 큐 내의 모든 객체 위치, 충돌 가능 영역과의 IoU, 해당 영역의 깊이 정보가 시퀀스로 구성되어 입력된다. 먼저 프레임별 깊이 정보는 Conv3D 계열 신경망을 통해 처리되어, Conv3D와 MaxPooling 연산을 반복함으로써 공간 해상도만을 축소하며 각 시점의 공간적 특성을 추출한다. IoU 및 바운딩 박스 구조적 정보는 Conv1D 계층을 통해 시점별로 처리되며, 깊이 기반 정보와 결합하여 통합된 feature 시퀀스를 구성한다. 이 통합 시퀸스는 Conv1D층을 통해 국소 시간 패턴을 추출하고, BiLSTM을 통해 객체의 움직임 및 충돌 경향성을 파악한다. 최종적으로, Fully Connected Layer를 통해 미래 시점의 충돌 가능성을 수치화하여 제시한다.\"\n}\n```",
  "Background": "```json\n{\n  \"section\": \"Background\",\n  \"improved\": \"시각장애인 보행 지원 연구는 주로 객체 인식 기술을 활용하여 장애물을 탐지하고, 경고나 안내를 제공하는 데 중점을 두어왔다. 시각장애인 보행 보조를 위한 조도 적응형 실시간 객체 탐지 연구[1]에서는 YOLO 알고리즘을 이용하여 객체 탐지를 통해 경고를 제공하는 방안을 제안하였다. 딥러닝 기반 시각장애인 보행 보조 시스템 연구[2]에서는 YOLO 모델을 활용하여 사람, 차량 등 주요 객체를 인식하고 음성 피드백을 제공하는 시스템을 소개하였다. 더 나아가, 시간적 연속성을 반영하려는 시도로 Erdaw 등[3]은 YOLO 모델에 Short-Term Memory (STM)를 결합하여 객체의 이동 정보를 반영하는 탐지 시스템을 제안하였다. GloSea6에서의 연구[4]에서는 YOLOv8을 활용하여 객체의 이동 방향, 크기 변화율 및 깊이 추정을 통해 이미지의 위험도를 측정하였다. 이러한 선행 연구들은 객체 인식, 위험도 추정, 보행 환경 고려 등 다양한 측면에서 시각장애인의 보행 안전 향상을 목표로 하고 있다. 그러나 대부분의 연구는 객체 인식에 주로 초점을 맞추며, 탐지된 정보를 기반으로 한 정적 위험 요소와 객체 분류에 집중하고 있다. 비전 기반으로 탐지된 객체의 시계열 움직임을 분석하고 이를 통해 충돌 위험성을 정량화하는 방식은 아직 충분히 연구되지 않았다. 본 연구는 연속된 프레임 간의 정보를 시계열적으로 해석하여 충돌 가능성을 정량적으로 분석한다는 점에서 기존 연구와 차별성을 가진다.\"\n}\n```"
}