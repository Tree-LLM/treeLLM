{
  "Discussion": "```json\n{\n  \"section\": \"Discussion\",\n  \"improved\": \"본 연구는 객체 인식, 충돌 가능 영역 설정, 깊이 추정 그리고 시계열 정보의 통합을 통해 시각장애인의 보행 중 충돌 위험을 예측하는 새로운 모델을 제안하였다. 이 모델은 충돌 가능 영역 및 해당 영역의 깊이 정보를 입력 특성으로 포함함으로써 기존의 위치 기반 예측보다 높은 정확도와 정밀도를 달성하였다. 또한, 통계 분석을 통해 이러한 입력 특성들이 실제 충돌과 유의미한 연관성을 갖는다는 점을 입증하였다. 특히, 다양한 시간적·공간적 정보를 효과적으로 결합하여 위험 상황을 사전에 인지하고 예측할 수 있는 구조를 제시한 것은 본 연구의 중요한 실용적 기여라 할 수 있다. 더 나아가, 향후 거리 추정이 가능한 센서나 스테레오 카메라 같은 보조 장비를 활용할 경우, 예측 정확도가 더욱 향상될 것으로 기대된다.\"\n}\n```",
  "Background": "```json\n{\n  \"section\": \"Background\",\n  \"improved\": \"시각장애인 보행 지원 연구는 주로 객체 인식 기술을 활용하여 장애물을 탐지하고, 이를 기반으로 경고 및 안내를 제공하는 데 중점을 두어왔다. 시각장애인 보행을 위한 조도 적응형 실시간 객체 탐지 연구[1]에서는 YOLO 모델을 활용하여 효과적인 경고 시스템을 제안하였다. 더 나아가, 딥러닝 기반 보행 보조 시스템 연구[2]는 YOLO 모델을 통해 사람이나 차량 등의 주요 객체를 인식하고, 이를 음성으로 안내하는 시스템을 개발하였다. 시간적 연속성을 반영하려는 연구도 있었으며, Erdaw et al.[3]은 YOLO 모델에 Short-Term Memory (STM)를 결합하여 객체의 이동 정보를 보다 정교하게 탐지하는 시스템을 제시하였다. GloSea6 연구에서는 YOLOv8 모델을 적용하여 객체의 이동 방향, 크기 변화율, 깊이를 측정함으로써 이미지의 위험도를 평가하였다[4]. 이처럼 선행 연구들은 객체 인식, 위험도 추정 및 보행 환경 분석 등을 통해 시각장애인의 보행 안전성을 제고하기 위해 다양한 접근을 시도해왔다. 그러나 대부분의 연구는 주로 정적인 위험 요소와 객체의 분류에 초점을 맞추고 있어, 비전 기반 객체의 시계열 움직임을 분석하여 충돌 위험성을 수치화하는 연구는 아직 부족한 실정이다. 본 연구는 연속 프레임 간의 정보를 시계열적으로 분석하여 충돌 가능성을 정량적으로 평가함으로써 기존 연구와 차별성을 지닌다.\"\n}\n```",
  "Abstract": "```json\n{\n  \"section\": \"Abstract\",\n  \"improved\": \"본 연구는 시각장애인의 보행 중 충돌 위험 예측을 목표로 하는 모델을 제안한다. 일반적으로 사람은 보행 시 무의식적으로 진행 방향을 인식하고, 그 경로 내 위험 요소를 감지하려는 경향을 보인다. 본 연구는 이러한 인지적 직관을 수학적으로 모델링하여 사용자 체형과 카메라 시야각을 토대로 '충돌 가능 영역'을 정의한다. 이 영역은 객체의 위치, 겹침 정도(IoU), 및 깊이 정보를 기반으로 입력된다. 제안된 충돌 가능 영역과 실제 충돌 간의 통계적 연관성을 자체 시뮬레이션 데이터로 검증한 결과, IoU 단일 지표만으로도 AUROC 0.702의 분류 성능을 보여 그 타당성을 입증하였다. 이러한 분석을 바탕으로, YOLO와 MiDaS를 활용하여 위치와 깊이 정보를 수집하고 이를 시계열 입력으로 구성하였다. 위치, IoU 및 깊이 정보는 각각 Conv1D 및 Conv3D를 통해 시공간적 특징이 추출되며, Conv1D–BiLSTM을 통해 시간적 패턴을 학습하여 충돌 여부를 이진 분류한다. 실험 결과, 최종 모델은 IoU와 깊이 정보를 결합하여 F1-score 0.7549를 기록하며 높은 예측 성능을 보였다.\"\n}\n```",
  "Introduction": "```json\n{\n  \"section\": \"Introduction\",\n  \"improved\": \"시각장애인의 독립적이고 안전한 보행은 이들의 삶의 질을 보장하기 위한 핵심 과제이다. 보행 중 발생할 수 있는 장애물이나 이동체와의 충돌 위험은 치명적일 수 있어, 이를 사전에 인지하고 방지하는 기술적 대응이 필수적이다. 최근 딥러닝을 기반으로 한 객체 탐지 기술의 진보로 다양한 환경에서 객체 인식이 가능해졌으나, 기존의 보행 지원 시스템은 주로 단일 프레임에 기반하여 객체를 인식하고 시계열적 변화와 공간적 맥락을 충분히 고려하지 못하는 한계를 가진다. 인간은 본능적으로 보행 중 진행 방향을 기준으로 앞으로 지나갈 영역을 인지하고 그 공간에서의 위험을 회피하려는 경향이 있다. 본 연구는 이러한 인지적 직관을 수학적으로 모델링하여, 사용자를 기준으로 정의된 충돌 가능 영역이라는 개념을 도입하고, 이를 통해 실질적인 보행 중 충돌 위험을 정량적으로 예측하는 모델을 제안한다. 충돌 가능 영역의 개념은 카메라 시야각과 사용자의 체형 정보를 기반으로 수학적으로 정의하며, 본 연구에서 제시한 개념은 실제 보행 중 충돌과 18만 개 이상의 시뮬레이션 시퀀스를 통해 통계적으로 유의미한 연관이 있음을 입증하였다. 제안된 충돌 위험 예측 모델은 인식된 객체와 충돌 가능 영역 간의 공간적 겹침 정도(IoU)와 깊이 정보를 활용하여 공간적, 시간적 특성을 추출한 뒤 이를 통합하여 충돌 가능성을 정량적으로 평가한다. 본 논문의 주요 공헌은 다음과 같다. 첫째, 시각장애인의 보행 중 충돌 위험을 정량화하기 위해 정의된 충돌 가능 영역을 자체 수집한 데이터로 검증하여, 이 영역 정보가 예측 지표로서 유의미함을 증명하였다. 둘째, 이 검증된 영역 지표를 바탕으로 IoU 및 깊이 정보를 통합하여 설계한 충돌 예측 모델은 F1-score 0.7549의 성능을 기록하며 높은 정확도를 달성하였다. 이 연구는 2024년 과학기술정통신부 및 정보통신기획평가원의 SW중심대학사업 지원을 받아 수행되었다. 셋째, 충돌 예측을 시계열 분류 문제로 정의하여 실험적으로 평가함으로써 실제 환경에서 실제로 활용 가능한 충돌 예측 모델의 가능성을 제시하였다.\"\n}\n```",
  "Method": "```json\n{\n  \"section\": \"Method\",\n  \"improved\": \"본 연구는 시각 장애인의 보행 시 발생할 수 있는 충돌 위험을 예측하기 위해 객체 탐지, 깊이 추정, 시계열 정보 분석을 통합한 모델을 설계하였다. 이 모델은 객체의 시계열적 움직임과 공간적 특성을 반영하여 미래 충돌 가능성을 정량적으로 평가한다. 이를 위해 보행 환경 내 위험 공간을 수학적으로 정의하여 충돌 가능 영역을 주요 입력 특성으로 활용하였다.\\n\\n3.1 충돌 가능 영역\\n보행 중 충돌 위험을 정량적으로 예측하기 위해 본 연구는 카메라 시야를 기준으로 충돌 가능성이 높은 공간을 수학적으로 정의하였다. 충돌 가능 영역은 사용자의 시야 높이, 어깨 너비, 카메라의 수평 및 수직 시야각(VFOV, HFOV)을 기반으로 계산되며, 실제 보행 경로에서 충돌 위험이 높은 영역을 삼각형 형태로 모델링한다. 이를 수학적으로 정의하기 위한 주요 변수로 시야 높이 h, 수직 시야각 θ₁, 수평 시야각 θ₂, 시야의 하단이 지면과 교차하는 수평 거리 d, 그리고 몸통 너비 a를 사용한다.\\n\\n그림 1은 수직 시점에서 본 수직 시야각을 나타낸다. 카메라 시야 하단과의 수평 거리 d는 다음과 같이 계산된다: d = h * cot(θ₁/2). 이는 사용자 기준 시야 높이 h에서 시야의 하단 경계까지의 수직선과 지면이 이루는 삼각형을 기반으로 도출된다. 그림 2는 수평 시점에서 본 수직 시야각을 나타내며, 계산된 거리 d를 통해 카메라의 수평 시야 하단 경계와 지면 교차 지점에서의 수평 폭 w는 w = 2d * tan(θ₂/2)로 계산된다. 수평 폭 w를 통해 충돌 가능 영역의 비율은 a/(2d * tan(θ₂/2))로 정의된다. 그림 3은 충돌 가능 영역에 대한 카메라 시야와 실제 보행 환경을 도식화한 것이다.\\n\\n3.2 모델 구조\\n본 연구의 모델 구조는 객체 인식, 깊이 추정, 시간 순 입력 처리, 충돌 위험 예측의 네 단계로 구성된다. 전체 시스템 흐름은 그림 4와 같다. 첫 번째 단계에서는 영상 스트림에서 프레임 단위로 다양한 객체를 YOLO v11 기반 객체 탐지 모델을 통해 인식하고, 위치를 바운딩 박스로 추출한다. 이때 각 객체의 좌표와 충돌 가능 영역과의 IoU를 계산하여 위험도 분석의 입력 특성으로 활용한다.\\n\\n두 번째 단계에서는 이미지의 각 픽셀에 대한 상대적인 깊이를 예측하여 위험도 판단의 정밀도를 향상시킨다. MiDaS 기반의 단일 이미지 깊이 추정 모델을 사용하여 각 픽셀의 깊이를 예측하고, 필요한 경우 충돌 가능 영역의 픽셀들만 선택하여 깊이 정보를 활용한다.\\n\\n세 번째 단계에서는 객체와 깊이 정보를 시간 순으로 분석하기 위해 고정 길이 슬라이딩 윈도우 큐를 사용한다. 이 큐에는 프레임에서 검출된 객체의 위치, 충돌 가능 영역과의 IoU, 해당 영역의 깊이 정보가 저장되며, 새로운 프레임이 들어오면 오래된 데이터는 제거되어 큐는 일정한 길이를 유지한다. 이를 통해 최근 시점의 연속 정보를 효과적으로 관리하며, 객체 움직임과 위험상황의 변화를 파악할 수 있다.\\n\\n마지막 단계에서는 큐에 저장된 시계열 데이터를 기반으로 향후 충돌 위험을 예측한다. 모든 객체의 위치, 충돌 가능 영역과의 IoU, 해당 영역의 깊이 정보가 하나의 시퀀스로 구성되어 입력된다. Conv3D 계열 신경망을 통해 각 프레임의 깊이 정보를 처리하여, 시간 축을 유지하면서 공간 해상도를 점진적으로 축소하여 공간적 특성을 추출한다. 동시에, 객체 정보인 IoU와 바운딩 박스 좌표는 Conv1D 계층을 통해 시점별 구조적 특징을 추출하고, 앞서 얻은 깊이 기반 정보와 결합하여 통합된 feature 시퀀스로 구성된다. 이 통합 시퀀스는 Conv1D 층을 통해 시간 패턴을 추출하며, BiLSTM을 통하여 객체의 움직임과 충돌 경향성을 반영하는 시간적 종속성을 파악한다. 마지막으로, Fully Connected Layer를 통해 미래 시점의 충돌 가능성을 정량화하여 나타낸다.\"\n}\n```",
  "Conclusion": "```json\n{\n  \"section\": \"Conclusion\",\n  \"improved\": \"본 연구에서는 객체 인식, 충돌 가능 영역의 정의, 깊이 추정, 시계열 정보의 통합을 통해 시각장애인의 보행 중 충돌 위험을 예측하는 모델을 제안하였다. 충돌 가능 영역 및 깊이 정보를 입력 특성으로 포함함으로써, 단순 위치 기반의 예측보다 높은 정확도와 정밀도를 달성하였다. 통계적 분석을 통해 이러한 입력 특성이 실제 충돌과 유의미한 연관성을 갖는 것 또한 입증하였다. 특히, 다양한 시간적 및 공간적 정보를 효과적으로 결합하여 위험 상황을 사전에 인지하고 예측할 수 있는 구조를 최초로 제시한 점에서 실용적 가치가 크다. 나아가, 거리 추정이 가능한 센서나 스테레오 카메라와 같은 보조 장비의 추가 활용을 통해 예측 정확도를 더 향상시킬 수 있을 것으로 기대된다.\"\n}\n```",
  "Related Work": "```json\n{\n  \"section\": \"Related Work\",\n  \"improved\": \"시각장애인 보행 지원에 관한 연구는 주로 객체 인식 기술을 활용하여 장애물을 탐지하고 그에 따른 경고나 안내를 제공하는 데 중점을 두어왔다. 예를 들어, 조도 적응형 실시간 객체 탐지[1] 연구에서는 YOLO 모델을 사용하여 경고 기능을 구현하였다. 딥러닝 기반의 시각장애인 보행 보조 시스템[2]에서는 YOLO를 활용하여 사람과 차량 등의 주요 객체를 인식하고, 음성 피드백을 제공하는 시스템을 제안하였다. 이에 더하여 시간적 연속성을 반영한 시도도 있었으며, Erdaw et al.[3]은 Short-Term Memory (STM)를 YOLO 모델에 결합하여 객체의 이동 정보를 반영한 탐지 시스템을 제시하였다. GloSea6에서의 연구[4]는 YOLOv8을 통해 객체의 이동 방향, 크기 변화율, 깊이 추정을 기반으로 이미지의 위험도를 평가하였다. 기존의 선행 연구들은 객체 인식, 위험도 추정, 보행 환경 등 시각장애인의 보행 안전을 향상시키기 위한 다양한 측면을 탐구하였다. 그러나 대부분의 연구는 객체 인식에만 초점을 맞추고 있으며, 탐지된 정보를 바탕으로 정적인 위험 요소나 객체 분류에 주로 의존하고 있다. 즉, 비전 기반으로 탐지된 객체의 시계열적 움직임을 분석하여 충돌 위험성을 정량화하는 접근은 충분히 다뤄지지 않았다. 본 연구는 연속된 프레임 간 정보를 시계열적으로 해석하여 충돌 가능성을 정량적으로 분석한다는 점에서 기존 연구와 차별성을 가질 것이다.\"\n}\n```"
}