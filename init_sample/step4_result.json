{
  "Related Work": "```json\n{\n  \"section\": \"Related Work\",\n  \"improved\": \"시각장애인 보행 지원에 관한 연구는 주로 객체 인식 기술을 활용하여 장애물을 탐지하고 해당 정보를 기반으로 경고나 안내를 제공하는 데 중점을 두고 있습니다. 시각장애인 보행 보조를 위한 조도 적응형 실시간 객체 탐지[1] 연구에서는 YOLO 모델을 사용하여 효율적인 경고를 제공하는 객체 탐지 방법을 제안하였습니다. 또한, 딥러닝 기반의 시각장애인 보행 보조 시스템[2]에서는 YOLO 모델을 활용하여 사람, 차량 등 주요 객체를 인식하고 음성 피드백을 제공하는 시스템을 제시하였습니다. 단순한 객체 인식 기술을 넘어 시간적 연속성을 고려한 연구도 존재합니다. Erdaw et al.[3]은 YOLO 모델에 Short-Term Memory (STM)를 결합하여 객체 이동 정보까지 아우르는 탐지 시스템을 개발하였습니다. GloSea6에서 YOLOv8을 활용한 시각장애인 보행자 위험 감지[4] 연구에서는 객체의 이동 방향, 크기 변화율, 깊이 추정 등을 통해 이미지의 위험성을 평가하였습니다. 그동안 진행된 연구들은 객체 인식, 위험도 평가, 보행 환경을 고려한 방법 등을 통해 시각장애인의 보행 안전성을 증진하고자 하였습니다. 그러나 대부분의 연구는 객체의 정적 인식에 초점을 맞추고, 탐지된 정보를 기반으로 위험 요소와 객체 분류에만 중점을 둡니다. 따라서 탐지된 객체의 시간적 움직임을 분석하여 충돌 위험성을 수치화하는 접근은 아직 충분히 탐구되지 않았습니다. 본 연구는 연속된 프레임 간 정보를 시간적으로 해석하여 충돌 가능성을 정량적으로 분석함으로써 기존 접근과 차별화를 모색합니다.\"\n}\n```",
  "Abstract": "```json\n{\n  \"section\": \"Abstract\",\n  \"improved\": \"본 연구는 시각장애인의 보행 시 충돌 위험을 예측하기 위한 모델을 제안한다. 보행 중 사람은 자연스럽게 진행 방향의 공간을 감지하고 그 안의 잠재적 위험 요소를 인지하게 된다. 이러한 인지적 직관을 수학적으로 모델링하여 사용자의 체형과 카메라의 시야각을 바탕으로 '충돌 가능 영역'을 정의하였다. 이 영역은 객체의 위치, 영역과의 겹침 정도(IoU), 깊이 정보를 입력으로 활용한다. 자체 시뮬레이션 데이터를 통해 충돌 가능 영역이 실제 충돌과 통계적으로 관련이 있음을 검증한 결과, IoU 지표만으로도 AUROC 0.702의 분류 성능을 확인하였다. 분석을 바탕으로, YOLO와 MiDaS를 사용하여 위치 및 깊이 정보를 추출하고 이를 시계열 입력으로 구성하였다. 위치, IoU, 깊이 정보는 각각 Conv1D와 Conv3D를 통해 시공간적 특징을 추출하며, Conv1D–BiLSTM을 통해 시간적 패턴을 학습하여 충돌 여부를 이진 분류한다. 최종적으로, IoU 및 깊이 정보를 함께 활용한 모델은 F1-점수 0.7549를 기록하며 뛰어난 예측 성능을 나타냈다.\"\n}\n```",
  "Conclusion": "```json\n{\n  \"section\": \"Conclusion\",\n  \"improved\": \"본 연구는 시각장애인의 안전한 보행을 돕기 위해 객체 인식, 충돌 가능 영역 정의, 깊이 추정, 그리고 시계열 정보를 통합하여 충돌 위험을 예측하는 모델을 제안하였다. 충돌 가능 영역과 깊이 정보를 입력 특성에 포함함으로써 기존의 단순 위치 기반 예측을 초월한 높은 정확도와 정밀도를 달성하였다. 통계적 분석을 통해 이러한 입력 특성이 실제 충돌과 유의한 연관성이 있음을 검증하였다. 특히, 본 연구는 다양한 시간적 및 공간적 정보를 통합하여 위험 상황을 사전에 예측할 수 있는 구조를 최초로 제시한 데서 실용적 가치를 지닌다. 향후 거리 추정이 가능한 센서나 스테레오 카메라 등의 보조 장비와의 통합을 통해 예측 정확도를 한층 더 향상시킬 수 있을 것으로 기대된다.\"\n}\n```",
  "Method": "```json\n{\n  \"section\": \"Method\",\n  \"improved\": \"본 연구는 시각 장애인의 보행 중 발생할 수 있는 충돌 위험을 예측하기 위해 객체 탐지, 깊이 추정 및 시계열 정보 분석을 통합한 모델을 설계하였다. 모델은 객체의 시계열적 움직임과 공간적 특성을 반영하여 미래 충돌 가능성을 정량적으로 평가한다. 이를 위해 보행 환경에서의 위험 공간을 수학적으로 정의한 '충돌 가능 영역'을 주요 입력 특성으로 활용한다.\\n\\n3.1 충돌 가능 영역\\n보행 중 충돌 위험을 정량적으로 예측하기 위해, 본 연구는 카메라 시야에서 충돌 가능성이 높은 공간을 수학적으로 정의하였다. 충돌 가능 영역은 사용자의 시야 높이, 어깨 너비, 그리고 카메라의 수평 및 수직 시야각(VFOV, HFOV)을 기반으로 계산된다. 이는 실제 보행 경로 상에서 충돌 위험이 높은 영역을 삼각형 형태로 모델링한다. 주요 변수는 다음과 같다: 시야 높이(ℎ), 수직 시야각(𝜃₁), 수평 시야각(𝜃₂), 시야의 하단이 지면과 만나는 수평거리(𝑑), 그리고 사람의 몸통 너비(𝑎).\\n\\n[그림1]은 수직 시점에서 본 카메라 시야각을 보여준다. 최하단과의 수평거리 𝑑는 𝑑 = ℎcot(𝜃₁/2)로 계산되며, 이는 사용자의 시야 높이 ℎ와 지면이 이루는 삼각형을 기반으로 도출된다. \\n\\n[그림2]는 수평 시점에서 본 카메라의 수평 시야각을 나타낸다. 앞서 구한 거리 𝑑를 통해 카메라의 수평 시야 하단 경계와 지면의 교차 지점에서의 수평 폭 𝑤는 𝑤 = 2𝑑tan(𝜃₂/2)로 계산 가능하다. 이를 바탕으로 실제 공간에 대한 충돌 가능 영역의 비율은 𝑎/(2𝑑tan(𝜃₂/2))로 구할 수 있다. 충돌 가능 영역은 카메라 시야에서의 지평선 중심점과 시야 하단의 수평 폭을 연결하여 설정된다. [그림3]은 이 공간에 대한 카메라 시야와 실제 보행 환경을 도식화한 것이다.\\n\\n3.2 모델 구조\\n연구의 모델 구조는 객체 인식, 깊이 추정, 시간 순 입력 처리, 그리고 충돌 위험 예측의 네 단계로 구성된다. [그림4]는 전체 시스템의 흐름을 나타낸다.\\n\\n첫 번째 단계에서는 영상 스트림의 각 프레임 단위로 객체를 인식한다. 이에 YOLO v11 기반 객체 탐지 모델을 사용하여 사람, 차량, 장애물 등 다양한 객체를 검출하고 그 위치 정보를 바운딩 박스 형태로 추출한다. 해당 객체의 좌표 정보와 충돌 가능 영역 간의 IoU(Intersection over Union)를 계산하여 위험도 분석에 활용한다.\\n\\n두 번째 단계에서는 이미지의 각 픽셀에 대한 상대적인 거리(깊이)를 예측하여 위험 판단의 정밀성을 개선한다. 이를 위해 MiDaS 기반 단일 이미지 깊이 추정 모델을 사용하며, 프레임을 입력 받아 각 픽셀의 깊이를 예측하고, 충돌 가능 영역에 해당하는 픽셀들을 선택적으로 추출하여 그 깊이 정보를 활용한다.\\n\\n세 번째 단계에서는 객체와 깊이 정보를 시간 순서에 따라 분석하기 위해 고정 길이의 슬라이딩 윈도우 큐(queue)를 사용한다. 이 큐에는 각 프레임에서 검출된 객체의 위치, 충돌 가능 영역과 IoU, 해당 영역의 깊이 정보가 저장된다. 새로운 프레임이 들어오면 오래된 데이터는 제거되고 최신 정보가 추가되며 항상 일정한 길이를 유지한다. 이를 통해 최근 시점의 연속적인 정보를 안정적으로 관리하여 객체의 움직임과 위험상황 변화를 효과적으로 탐지할 수 있다.\\n\\n마지막 단계에서는 큐에 저장된 시계열 데이터를 기반으로 향후 충돌 위험을 예측한다. 큐에 있는 모든 객체 위치, 충돌 가능 영역 간의 IoU, 그리고 해당 영역의 깊이 정보가 하나의 시퀀스로 구성되어 입력된다. 먼저, 프레임별 깊이 정보는 Conv3D 신경망을 통해 처리되며, 시간축을 유지한 상태에서 공간 해상도만 점진적으로 축소하여 각 시점의 공간적 특성을 효과적으로 추출한다. 반면, IoU 및 바운딩 박스 좌표 등의 객체 관련 정보는 Conv1D 계층을 통해 시점별 구조적 특징을 추출하며, 깊이 기반 정보와 시점별로 결합되어 통합된 feature 시퀀스로 구성된다. 이 시퀀스는 Conv1D 층을 통해 지역적 시간 패턴을 추출하고, BiLSTM을 통해 객체의 움직임과 충돌 경향성을 반영하는 시간적 종속성을 파악한다. 마지막으로, Fully Connected Layer를 통해 미래 시점의 충돌 가능성을 수치화하여 나타낸다.\"\n}\n```",
  "Discussion": "```json\n{\n  \"section\": \"Discussion\",\n  \"improved\": \"본 연구는 객체 인식 및 충돌 가능 영역의 정의, 깊이 추정, 시계열 정보의 통합을 통해 시각장애인의 보행 중 충돌 위험을 예측하는 모델을 제시하였다. 충돌 가능 영역과 해당 깊이 정보를 입력 특성으로 포함함으로써, 이전의 단순 위치 기반 예측보다 높은 정확도와 정밀도를 확보하였다. 또한, 통계적 분석을 통해 이러한 입력 특성들이 실제 충돌과 유의한 상관성을 지님을 확인하였다. 특히, 다양한 시간적‧공간적 정보를 효과적으로 결합하여 위험 상황을 사전에 인지하고 예측하는 구조를 제시한 점은 실용적 가치를 높인다. 향후 거리(깊이) 추정이 가능한 센서나 스테레오 카메라 등 보조 장비 활용 시, 예측 정확도가 더욱 향상될 것으로 기대된다.\"\n}\n```",
  "Background": "```json\n{\n  \"section\": \"Background\",\n  \"improved\": \"시각장애인의 안전한 보행을 지원하기 위한 연구는 주로 객체 인식 기술을 활용한 장애물 탐지와 이를 기반으로 경고나 안내를 제공하는 데 초점을 맞추어 왔습니다. 시각장애인 보행 보조를 위한 조도 적응형 실시간 객체 탐지 연구[1]에서는 YOLO를 활용하여 장애물을 탐지하고 경고를 제공하는 방법을 제시하였습니다. 또한, 딥러닝 기반의 시각장애인 보행 보조 시스템 연구[2]에서는 YOLO 모델을 통해 사람이나 차량 등 주요 객체를 인식하고 음성 피드백을 제공하는 시스템이 제안되었습니다. 시간적 연속성을 반영하려는 시도로서 Erdaw et al.[3]은 YOLO 모델과 Short-Term Memory (STM)를 결합하여 객체의 이동 정보를 반영하는 탐지 시스템을 제안하였습니다. GloSea6 연구에서는 YOLOv8을 활용하여 객체의 이동 방향, 크기 변화율, 깊이 추정을 통해 시각장애인 보행자의 위험을 감지하는 방법을 연구하였습니다[4]. 이처럼 기존 연구들은 객체 인식, 위험도 추정, 보행 환경 고려 등 다양한 측면에서 시각장애인의 보행 안전을 향상시키기 위해 노력하고 있습니다. 그러나, 많은 연구가 주로 객체 인식에만 집중하고 있으며, 탐지된 정보를 기반으로 정적인 위험 요소나 객체의 분류에 집중하는 경향이 있습니다. 비전 기반으로 탐지된 객체의 시계열적 움직임을 분석하고 이를 통해 충돌 위험성을 정량화하는 방식은 아직 충분히 탐구되지 않았습니다. 본 연구는 연속 프레임 간 정보를 시계열적으로 해석하여 충돌 가능성을 정량적으로 분석함으로써 기존 연구와 차별성을 두려 합니다.\"\n}\n```",
  "Introduction": "```json\n{\n  \"section\": \"Introduction\",\n  \"improved\": \"시각장애인의 독립적이고 안전한 보행은 삶의 질 보장을 위한 핵심 과제입니다. 특히, 보행 과정에서 발생할 수 있는 장애물이나 이동체와의 충돌 위험은 생명과 직결되는 심각한 문제로, 이를 사전에 인식하고 예방하기 위한 기술적 대응이 요구됩니다. 최근 딥러닝 기반 객체 탐지 기술의 발전으로 다양한 환경에서 객체 인식이 가능해졌지만, 기존 보행 지원 시스템은 주로 단일 프레임 기반의 객체 판단에 머무르며, 시계열적 변화나 공간적 맥락을 충분히 고려하지 못하는 한계를 지닙니다. 사람은 보행 중 무의식적으로 자신의 진행 방향을 기준으로 미래의 경로를 인식하고, 해당 공간에서의 위험 요소를 회피하려는 경향이 있습니다. 본 연구는 이러한 인지적 직관을 수학적으로 모델링하여, 사용자를 기준으로 정의된 '충돌 가능 영역'이라는 개념을 토대로 실제 보행 중의 위험을 정량적으로 예측하는 모델을 제안합니다. 충돌 가능 영역의 개념은 카메라 시야각과 사용자의 체형 정보를 바탕으로 수학적으로 정의되며, 본 연구에서 정의된 개념은 실제 보행 중 충돌과 통계적으로 유의미한 상관성을 동일한 것으로 18만 개 이상의 시뮬레이션 시퀀스를 통해 입증하였습니다. 제안된 충돌 위험 예측 모델은 인식된 객체와 충돌 가능 영역 간의 겹침 정도(IoU) 및 깊이 정보를 바탕으로 공간적, 시간적 특성을 추출하여 이를 통합함으로써 충돌 가능성을 정량화합니다. 본 논문의 주요 공헌은 다음과 같습니다. 첫째, 시각장애인의 보행 중 충돌 위험을 정량화하기 위해 정의된 충돌 가능 영역의 유효성을 수집한 데이터 기반으로 통계적으로 검증하고, 이를 통해 해당 영역 정보가 예측 지표로 사용될 때의 의미를 입증하였습니다. 둘째, 검증된 영역 관련 지표를 바탕으로 IoU 및 깊이 정보를 통합하여 설계된 충돌 예측 모델은 F1-score 0.7549의 성능을 기록하며 높은 정확도를 달성하였습니다. 이 연구는 과학기술정보통신부 및 정보통신기획평가원의 SW중심대학사업 지원을 받아 수행되었습니다. 셋째, 충돌 여부를 시계열 분류 문제로 정의하고 이를 실험적으로 평가하여, 실제 환경에서 활용 가능한 충돌 예측 모델의 가능성을 제시하였습니다.\"\n}\n```"
}