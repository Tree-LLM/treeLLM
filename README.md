# TreeLLM - Advanced Paper Analysis System

λ…Όλ¬Έ λ¶„μ„μ„ μ„ν• κ³ κΈ‰ LLM νμ΄ν”„λΌμΈ μ‹μ¤ν…

## μ£Όμ” νΉμ§•

### π€ ν•μ΄νΌνλΌλ―Έν„° μµμ ν™”
- **μ„Έλ°€ν• νλΌλ―Έν„° μ μ–΄**: Temperature, Top-p, Max Tokens λ“± λ¨λ“  μ£Όμ” νλΌλ―Έν„° μ΅°μ • κ°€λ¥
- **ν”„λ¦¬μ…‹ μ‹μ¤ν…**: Fast, Balanced, Thorough, Research ν”„λ¦¬μ…‹ μ κ³µ
- **λ¨λΈλ³„ μµμ ν™”**: GPT-4o, GPT-4, GPT-3.5-turboλ³„ μµμ  μ„¤μ •
- **λ³‘λ ¬ μ²λ¦¬**: λ©€ν‹°μ¤λ λ“λ¥Ό ν™μ©ν• λΉ λ¥Έ μ²λ¦¬

### π“ κ³ κΈ‰ λ¶„μ„ κΈ°λ¥
- **7λ‹¨κ³„ λ¶„μ„ νμ΄ν”„λΌμΈ**
  1. Split - λ¬Έμ„ μ„Ήμ… λ¶„ν• 
  2. Build - LLM ν”„λ΅¬ν”„νΈ μ‹¤ν–‰
  3. Fuse - νΈλ¦¬ κµ¬μ΅° μƒμ„±
  4. Audit - ν’μ§ κ°μ‚¬
  5. Edit Pass 1 - 1μ°¨ νΈμ§‘
  6. Global Check - μ „μ—­ μΌκ΄€μ„± κ²€μ‚¬
  7. Edit Pass 2 - μµμΆ… νΈμ§‘

### π― μ§€λ¥ν• κΈ°λ¥
- **μ μ‘ν• νΈλ¦¬ κµ¬μ΅°**: λ…Όλ¬Έ κµ¬μ΅°μ— λ§μ¶ λ™μ  νΈλ¦¬ μƒμ„±
- **ν’μ§ μ μ μ‹μ¤ν…**: κ° λ‹¨κ³„λ³„ ν’μ§ ν‰κ°€ λ° ν”Όλ“λ°±
- **μ‹¤μ‹κ°„ μ¤νΈλ¦¬λ°**: λ¶„μ„ μ§„ν–‰ μƒν™© μ‹¤μ‹κ°„ ν™•μΈ
- **λ‹¤μ–‘ν• νμΌ μ§€μ›**: PDF, DOCX, TXT, Markdown

## μ„¤μΉ λ°©λ²•

### 1. μ €μ¥μ† ν΄λ΅ 
```bash
git clone https://github.com/yourusername/TreeLLM.git
cd TreeLLM
```

### 2. κ°€μƒν™κ²½ μ„¤μ •
```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
```

### 3. μμ΅΄μ„± μ„¤μΉ
```bash
pip install -r requirements.txt
```

### 4. ν™κ²½ λ³€μ μ„¤μ •
```bash
export OPENAI_API_KEY="your-api-key-here"
```

## μ‚¬μ© λ°©λ²•

### μ›Ή μΈν„°νμ΄μ¤ (κ¶μ¥)
```bash
python app_v2.py
```
λΈλΌμ°μ €μ—μ„ `http://localhost:5001` μ ‘μ†

### μ»¤λ§¨λ“ λΌμΈ
```bash
# κΈ°λ³Έ μ‚¬μ©
python v2/OrchestratorV2.py sample/example.txt

# ν”„λ¦¬μ…‹ μ‚¬μ©
python v2/OrchestratorV2.py sample/example.txt --preset research

# μ»¤μ¤ν…€ μ„¤μ •
python v2/OrchestratorV2.py sample/example.txt --temperature 0.2 --model gpt-4

# μ¤νΈλ¦¬λ° λ¨λ“
python v2/OrchestratorV2.py sample/example.txt --stream
```

## μ„¤μ • ν”„λ¦¬μ…‹

### Fast (λΉ λ¥Έ μ²λ¦¬)
- Temperature: 0.5
- λ³‘λ ¬ μ²λ¦¬: 5 workers
- κΈ°λ³Έμ μΈ λ¶„μ„μ— μ ν•©

### Balanced (κ· ν•)
- Temperature: 0.3
- λ³‘λ ¬ μ²λ¦¬: 3 workers
- μΌλ°μ μΈ λ…Όλ¬Έ λ¶„μ„μ— κ¶μ¥

### Thorough (μ •λ°€)
- Temperature: 0.2
- λ³‘λ ¬ μ²λ¦¬: 2 workers
- μ„Έλ°€ν• λ¶„μ„μ΄ ν•„μ”ν• κ²½μ°

### Research (μ—°κµ¬μ©)
- Temperature: 0.1
- λ³‘λ ¬ μ²λ¦¬: 2 workers
- μµκ³  ν’μ§μ λ¶„μ„

## ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •

### config.py κµ¬μ΅°
```python
config = TreeLLMConfig(
    model=ModelConfig(
        model_name="gpt-4o",
        temperature=0.3,
        top_p=0.3,
        max_tokens=4096
    ),
    build=BuildConfig(
        parallel_processing=True,
        max_workers=3,
        retry_attempts=3
    ),
    audit=AuditConfig(
        strictness_level="medium",
        detailed_feedback=True
    )
)
```

### μ»¤μ¤ν…€ μ„¤μ • μμ‹
```python
from config import load_config

# ν”„λ¦¬μ…‹ κΈ°λ° μ»¤μ¤ν„°λ§μ΄μ§•
config = load_config(
    "thorough",
    model={"temperature": 0.15},
    debug_mode=True
)

orchestrator = OrchestratorV2(config)
```

## API μ—”λ“ν¬μΈνΈ

### POST /api/analyze
λ…Όλ¬Έ λ¶„μ„ μ‹¤ν–‰ (λ™κΈ°)

### POST /api/analyze/stream
λ…Όλ¬Έ λ¶„μ„ μ‹¤ν–‰ (μ¤νΈλ¦¬λ°)

### GET /api/presets
μ‚¬μ© κ°€λ¥ν• ν”„λ¦¬μ…‹ λ©λ΅

### GET /api/config/{preset}
νΉμ • ν”„λ¦¬μ…‹μ μƒμ„Έ μ„¤μ •

### GET /api/status
μ‹μ¤ν… μƒνƒ ν™•μΈ

## ν”„λ΅μ νΈ κµ¬μ΅°
```
TreeLLM/
β”β”€β”€ config.py              # ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •
β”β”€β”€ v2/
β”‚   β””β”€β”€ OrchestratorV2.py  # λ©”μΈ νμ΄ν”„λΌμΈ (μµμ ν™” λ²„μ „)
β”β”€β”€ module/                # κ° λ‹¨κ³„λ³„ λ¨λ“
β”‚   β”β”€β”€ split.py          # λ¬Έμ„ λ¶„ν• 
β”‚   β”β”€β”€ build.py          # LLM ν”„λ΅¬ν”„νΈ μ‹¤ν–‰
β”‚   β”β”€β”€ fuse.py           # νΈλ¦¬ κµ¬μ΅° μƒμ„±
β”‚   β”β”€β”€ audit.py          # ν’μ§ κ°μ‚¬
β”‚   β”β”€β”€ edit_pass1.py     # 1μ°¨ νΈμ§‘
β”‚   β”β”€β”€ global_check.py   # μ „μ—­ κ²€μ‚¬
β”‚   β””β”€β”€ edit_pass2.py     # μµμΆ… νΈμ§‘
β”β”€β”€ prompts/              # ν”„λ΅¬ν”„νΈ ν…ν”λ¦Ώ
β”β”€β”€ app_v2.py            # Flask μ›Ή μ•±
β””β”€β”€ templates/           # μ›Ή UI ν…ν”λ¦Ώ
```

## μ„±λ¥ μµμ ν™” ν

1. **λ³‘λ ¬ μ²λ¦¬ ν™μ©**
   - μ—¬λ¬ ν”„λ΅¬ν”„νΈλ¥Ό λ™μ‹μ— μ‹¤ν–‰ν•μ—¬ μ†λ„ ν–¥μƒ
   - CPU μ½”μ–΄ μμ— λ§μ¶° max_workers μ΅°μ •

2. **μΊμ‹± ν™μ©**
   - μ¤‘κ°„ κ²°κ³Ό μ €μ¥μΌλ΅ μ¬μ‹¤ν–‰ μ‹κ°„ λ‹¨μ¶•
   - save_intermediate_results μ„¤μ • ν™μ©

3. **μ μ ν• ν”„λ¦¬μ…‹ μ„ νƒ**
   - λ…Όλ¬Έ κΈΈμ΄μ™€ λ³µμ΅λ„μ— λ”°λΌ μ μ ν• ν”„λ¦¬μ…‹ μ„ νƒ
   - μ΄κΈ° ν…μ¤νΈλ” Fast ν”„λ¦¬μ…‹μΌλ΅ μ‹μ‘

4. **λ©”λ¨λ¦¬ κ΄€λ¦¬**
   - λ€μ©λ‰ PDF μ²λ¦¬ μ‹ μ¶©λ¶„ν• λ©”λ¨λ¦¬ ν™•λ³΄
   - ν•„μ”μ‹ μ„Ήμ…λ³„ μ²λ¦¬ κ³ λ ¤

## λ¬Έμ  ν•΄κ²°

### API ν‚¤ μ¤λ¥
```bash
export OPENAI_API_KEY="sk-..."
```

### λ©”λ¨λ¦¬ λ¶€μ΅±
- max_section_length νλΌλ―Έν„° μ΅°μ •
- λ³‘λ ¬ μ²λ¦¬ worker μ κ°μ†

### νƒ€μ„μ•„μ›ƒ μ¤λ¥
- timeout νλΌλ―Έν„° μ¦κ°€
- retry_attempts μ¦κ°€

## κΈ°μ—¬ λ°©λ²•

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## λΌμ΄μ„Όμ¤

MIT License - μμ„Έν• λ‚΄μ©μ€ LICENSE νμΌ μ°Έμ΅°

## λ¬Έμ

- Issue Tracker: [GitHub Issues](https://github.com/yourusername/TreeLLM/issues)
- Email: your.email@example.com
